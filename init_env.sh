#!/usr/bin/env bash
###
 # @Author: Audrey Yang 97855340+wyang10@users.noreply.github.com
 # @Date: 2025-11-06 01:06:31
 # @LastEditors: Audrey Yang 97855340+wyang10@users.noreply.github.com
 # @LastEditTime: 2025-11-06 11:48:52
 # @FilePath: /airflow_dbt_demo/init_env.sh
 # @Description: è¿™æ˜¯é»˜è®¤è®¾ç½®,è¯·è®¾ç½®`customMade`, æ‰“å¼€koroFileHeaderæŸ¥çœ‹é…ç½® è¿›è¡Œè®¾ç½®: https://github.com/OBKoro1/koro1FileHeader/wiki/%E9%85%8D%E7%BD%AE
### 
set -euo pipefail

PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]:-$0}")" && pwd)"
echo "ðŸ“ Project root: $PROJECT_ROOT"

# 1) æœ¬åœ° dbt è™šæ‹ŸçŽ¯å¢ƒï¼ˆç”¨äºŽä½ åœ¨å®¿ä¸»æœºä¸Šè·‘ dbt å‘½ä»¤ï¼‰
VENV_DIR="$PROJECT_ROOT/data_pipeline/.venv"

# æ£€æŸ¥ venv æ˜¯å¦å­˜åœ¨ä»¥åŠæ˜¯å¦â€œé™ˆæ—§/æŸåâ€ï¼ˆä¾‹å¦‚é¡¹ç›®ç›®å½•è¢«ç§»åŠ¨å¯¼è‡´ shebang æŒ‡å‘æ—§è·¯å¾„ï¼‰
broken_venv() {
  # 1) ç›®å½•ä¸å­˜åœ¨
  [[ -d "$VENV_DIR" ]] || return 0
  # 2) python å¯æ‰§è¡Œä¸å­˜åœ¨
  [[ -x "$VENV_DIR/bin/python" ]] || return 0
  # 3) è¯•è·‘ä¸€ä¸ªæœ€ç®€å•çš„å‘½ä»¤ï¼Œå¤±è´¥åˆ™è®¤ä¸ºæŸå
  "$VENV_DIR/bin/python" -c 'import sys; assert sys.version_info.major >= 3' >/dev/null 2>&1 || return 0
  # 4) æ£€æŸ¥ pip shebang æ˜¯å¦æŒ‡å‘å½“å‰ venvï¼ˆç›®å½•ç§»åŠ¨åŽå¸¸è§é—®é¢˜ï¼‰
  local pip_head
  pip_head="$(head -n1 "$VENV_DIR/bin/pip" 2>/dev/null || true)"
  if [[ "$pip_head" == "#!"* ]] && [[ "$pip_head" != "#!$VENV_DIR/"* ]]; then
    return 0
  fi
  return 1 # ä¸æŸå
}

if broken_venv; then
  if [[ -d "$VENV_DIR" ]]; then
    echo "ðŸ§¹ Removing stale/broken venv ..."
    rm -rf "$VENV_DIR"
  fi
  echo "ðŸ Creating Python venv for dbt ..."
  python3 -m venv "$VENV_DIR"
fi

# shellcheck disable=SC1091
source "$VENV_DIR/bin/activate"
echo "âœ… venv: $VIRTUAL_ENV"

# å¯é€‰ï¼šå¦‚æžœæ²¡è£…ï¼Œå¸®ä½ è£… dbt-snowflake
pip show dbt-snowflake >/dev/null 2>&1 || {
  echo "ðŸ“¦ Installing dbt + adapter (local)..."
  pip install -q "dbt-core>=1.10,<2" "dbt-snowflake>=1.10,<2"
}

# 2) è®¾ç½® dbt ä½¿ç”¨çš„ profiles ç›®å½•
export DBT_PROFILES_DIR="$PROJECT_ROOT/data_pipeline"
echo "ðŸ”§ DBT_PROFILES_DIR=$DBT_PROFILES_DIR"

# 3) æ‰¹é‡åŠ è½½ Snowflake çŽ¯å¢ƒå˜é‡ï¼ˆä¾›æœ¬åœ° dbt è°ƒè¯•ï¼‰
if [[ -f "$PROJECT_ROOT/airflow/.env" ]]; then
  set -a
  # shellcheck disable=SC1091
  source "$PROJECT_ROOT/airflow/.env"
  set +a
  echo "ðŸ” Loaded env from airflow/.env"

  # If the env is configured for containers (e.g. /opt/airflow/secrets/...),
  # remap to a local file under ./secrets/ so `dbt` on the host can still run.
  if [[ -n "${SNOWFLAKE_PRIVATE_KEY_PATH:-}" ]] && [[ ! -f "${SNOWFLAKE_PRIVATE_KEY_PATH}" ]]; then
    key_base="$(basename "${SNOWFLAKE_PRIVATE_KEY_PATH}")"
    local_key="$PROJECT_ROOT/secrets/$key_base"
    if [[ -f "$local_key" ]]; then
      export SNOWFLAKE_PRIVATE_KEY_PATH="$local_key"
      echo "ðŸ”‘ Remapped SNOWFLAKE_PRIVATE_KEY_PATH -> $SNOWFLAKE_PRIVATE_KEY_PATH (host)"
    fi
  fi
else
  echo "âš ï¸  Missing: $PROJECT_ROOT/airflow/.env  (è¯·å…ˆåˆ›å»ºå¹¶å†™å…¥ Snowflake å˜é‡)"
fi

# 4) æ‰“å°å…³é”®çŽ¯å¢ƒå˜é‡ç¡®è®¤ï¼ˆæŽ©ç å¯†ç ï¼‰
echo "ðŸ”Ž Env check:"
( printenv | grep -E '^(DBT_PROFILES_DIR|DBT_TARGET|SNOWFLAKE_(ACCOUNT|USER|ROLE|WAREHOUSE|DATABASE|SCHEMA))$' || true ) \
  | sed 's/\(SNOWFLAKE_PASSWORD=\).*/\1********/'

# 5) æœ¬åœ° dbt è‡ªæ£€ï¼ˆå¯é€‰ï¼‰
if [[ -z "${SNOWFLAKE_ACCOUNT:-}" ]]; then
  echo "ðŸ§ª No Snowflake credentials detected -> running: dbt parse (project=data_pipeline)"
  dbt parse --project-dir "$PROJECT_ROOT/data_pipeline" --profiles-dir "$PROJECT_ROOT/data_pipeline" || true
else
  echo "ðŸ§ª Running: dbt debug (project=data_pipeline)"
  dbt debug --project-dir "$PROJECT_ROOT/data_pipeline" --profiles-dir "$PROJECT_ROOT/data_pipeline" || true
fi

cat <<'TIPS'

âœ… çŽ¯å¢ƒå·²å°±ç»ªï¼

å¸¸ç”¨æœ¬åœ°å‘½ä»¤ï¼š
  dbt ls
  dbt run --select path:models/bronze
  dbt run --select path:models/silver
  dbt run --select path:models/gold
  dbt build

ä¸‹ä¸€æ­¥ï¼ˆDocker å¯åŠ¨ Airflowï¼‰ï¼š
  docker compose up -d
  # æ‰“å¼€ http://localhost:8080  ï¼ˆairflow/airflowï¼‰

TIPS
