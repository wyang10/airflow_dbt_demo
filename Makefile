# Makefile â€” Airflow + dbt + Snowflake å¿«æ·æ“ä½œå°
# æ”¾ç½®è·¯å¾„ï¼šé¡¹ç›®æ ¹ç›®å½•ï¼ˆå« docker-compose.yml / init_env.shï¼‰
# ç”¨æ³•ï¼šmake help

SHELL := /bin/bash
PROJECT_ROOT := $(abspath $(dir $(lastword $(MAKEFILE_LIST))))
COMPOSE := docker compose -f $(PROJECT_ROOT)/docker-compose.yml
AIRFLOW_URL ?= http://localhost:8080
AIRFLOW_UID ?= $(shell id -u)

OPEN := open
ifeq ($(shell command -v xdg-open >/dev/null 2>&1; echo $$?),0)
  OPEN := xdg-open
endif

.PHONY: help ########## é»˜è®¤å¸®åŠ©
help: ## æ˜¾ç¤ºå¯ç”¨å‘½ä»¤
	@echo ""
	@echo "ğŸŒˆ Airflow + dbt + Snowflake æŒ‡ä»¤å°æŠ„"
	@echo ""
	@awk 'BEGIN {FS":.*##"; printf "%-28s %s\n","å‘½ä»¤","è¯´æ˜"; printf "%-28s %s\n","----","----"} /^[a-zA-Z0-9_.-]+:.*##/ { printf "%-28s %s\n", $$1, $$2 }' $(MAKEFILE_LIST)
	@echo ""

# ---------------------------
# ç¯å¢ƒåˆå§‹åŒ– / æœ¬åœ° dbt
# ---------------------------
.PHONY: env
env:  ## ä¸€é”®åˆå§‹åŒ–æœ¬åœ°ç¯å¢ƒï¼ˆsource init_env.shï¼‰
	@test -x "$(PROJECT_ROOT)/init_env.sh" || { echo "âŒ æ‰¾ä¸åˆ° init_env.sh æˆ–æ— æ‰§è¡Œæƒé™"; exit 1; }
	@source "$(PROJECT_ROOT)/init_env.sh"

.PHONY: dbt-debug
dbt-debug: env ## dbt debug è‡ªæ£€
	@cd "$(PROJECT_ROOT)/data_pipeline" && dbt debug

.PHONY: dbt-parse
dbt-parse: env ## dbt parseï¼ˆè§£æé¡¹ç›®ï¼‰
	@cd "$(PROJECT_ROOT)/data_pipeline" && dbt parse

.PHONY: dbt-ls
dbt-ls: env ## åˆ—å‡ºæ‰€æœ‰æ¨¡å‹
	@cd "$(PROJECT_ROOT)/data_pipeline" && dbt ls

.PHONY: dbt-ls-bronze dbt-ls-silver dbt-ls-gold
dbt-ls-bronze: env ## åˆ—å‡º bronze æ¨¡å‹
	@cd "$(PROJECT_ROOT)/data_pipeline" && dbt ls --select 'path:models/bronze'
dbt-ls-silver: env ## åˆ—å‡º silver æ¨¡å‹
	@cd "$(PROJECT_ROOT)/data_pipeline" && dbt ls --select 'path:models/silver'
dbt-ls-gold:   env ## åˆ—å‡º gold æ¨¡å‹
	@cd "$(PROJECT_ROOT)/data_pipeline" && dbt ls --select 'path:models/gold'

.PHONY: dbt-run-bronze dbt-run-silver dbt-run-gold dbt-build
dbt-run-bronze: env ## ä»…è·‘ bronze
	@cd "$(PROJECT_ROOT)/data_pipeline" && dbt run --select 'path:models/bronze'
dbt-run-silver: env ## ä»…è·‘ silver
	@cd "$(PROJECT_ROOT)/data_pipeline" && dbt run --select 'path:models/silver'
dbt-run-gold:   env ## ä»…è·‘ gold
	@cd "$(PROJECT_ROOT)/data_pipeline" && dbt run --select 'path:models/gold'
dbt-build:      env ## å…¨é‡æ„å»ºï¼ˆå«æµ‹è¯•ï¼‰
	@cd "$(PROJECT_ROOT)/data_pipeline" && dbt build

.PHONY: dbt-docs
dbt-docs: env ## ç”Ÿæˆ + æœ¬åœ°é¢„è§ˆæ–‡æ¡£ï¼ˆå‰å°ï¼‰
	@cd "$(PROJECT_ROOT)/data_pipeline" && dbt docs generate && dbt docs serve

# ---------------------------
# Docker / Airflow ç®¡ç†
# ---------------------------
.PHONY: up rebuild fresh logs down destroy ps open
up:  ## å¯åŠ¨ï¼ˆå«åˆå§‹åŒ–ï¼‰ï¼Œè‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨
	@AIRFLOW_UID=$(AIRFLOW_UID) $(COMPOSE) run --rm airflow-init
	@AIRFLOW_UID=$(AIRFLOW_UID) $(COMPOSE) up -d
	@$(MAKE) open

rebuild: ## é‡æ–°æ„å»ºé•œåƒå¹¶å¯åŠ¨
	@AIRFLOW_UID=$(AIRFLOW_UID) $(COMPOSE) build --pull
	@$(MAKE) up

fresh: ## æ¸…å·é‡èµ·ï¼ˆå±é™©ï¼šä¼šåˆ é™¤å·ï¼‰
	@AIRFLOW_UID=$(AIRFLOW_UID) $(COMPOSE) down -v || true
	@$(MAKE) up

logs: ## è·Ÿéš webserver & scheduler æ—¥å¿—
	@$(COMPOSE) logs -f webserver scheduler

down: ## åœæ­¢å®¹å™¨ï¼ˆä¿ç•™å·ï¼‰
	@$(COMPOSE) down

destroy: ## åœæ­¢å®¹å™¨ + åˆ é™¤å· + æ¸…ç†ç¼“å­˜ï¼ˆå±é™©æ“ä½œï¼‰
	@$(COMPOSE) down -v || true
	@docker system prune -af || true

ps: ## æŸ¥çœ‹å®¹å™¨çŠ¶æ€
	@$(COMPOSE) ps

open: ## æ‰“å¼€ Airflow UI
	@echo "æ‰“å¼€ $(AIRFLOW_URL) ..."
	@$(OPEN) "$(AIRFLOW_URL)" >/dev/null 2>&1 || true

# ---------------------------
# å›å½’/éªŒè¯
# ---------------------------
.PHONY: validate validate-daily validate-pipelines
validate: ## ä¸€é”®è§¦å‘å¹¶ç­‰å¾…å…¨éƒ¨ DAG æˆåŠŸï¼ˆdbt_daily + pipelinesï¼‰
	@bash scripts/validate.sh

validate-daily: ## ä»…éªŒè¯ dbt_daily
	@bash scripts/validate.sh dbt_daily

validate-pipelines: ## ä»…éªŒè¯ä¸¤ä¸ª pipeline DAG
	@bash scripts/validate.sh dbt_daily_pipeline dbt_layered_pipeline

.PHONY: clear-failed clear-failed-hard
clear-failed: ## æ¸…ç†ä¸‰æ¡ DAG çš„å¤±è´¥ä»»åŠ¡å®ä¾‹ï¼ˆä¿ç•™è¿è¡Œè®°å½•ï¼‰
	@bash scripts/clear_failed.sh

clear-failed-hard: ## åˆ é™¤ä¸‰æ¡ DAG çš„å¤±è´¥è¿è¡Œï¼ˆå±é™©ï¼šä¼šåˆ é™¤å¤±è´¥ run è®°å½•ï¼‰
	@bash scripts/clear_failed.sh --delete-runs

# ---------------------------
# Airflow è¿ç»´ä¾¿æ·å‘½ä»¤
# ---------------------------
.PHONY: logs-web logs-sch restart-sch clear-queue
logs-web: ## ä»…è·Ÿéš webserver æ—¥å¿—
	@$(COMPOSE) logs -f webserver
logs-sch: ## ä»…è·Ÿéš scheduler æ—¥å¿—
	@$(COMPOSE) logs -f scheduler

restart-sch: ## é‡å¯ scheduler
	@$(COMPOSE) restart scheduler

clear-queue: ## æ¸…ç©º worker/scheduler é˜Ÿåˆ—ç¼“å­˜ï¼ˆå¿…è¦æ—¶ï¼‰
	@$(COMPOSE) exec -T scheduler bash -lc "airflow jobs check --job-type SchedulerJob || true; rm -rf /opt/airflow/logs/* || true; echo 'queue cleared.'"

# ---------------------------
# å¿«æ·å¥åº·æ£€æŸ¥
# ---------------------------
.PHONY: health
health: ## å¥åº·æ£€æŸ¥ï¼ˆAirflow Web / Schedulerï¼‰
	@echo "Check webserver health..."
	@curl -fsS "$(AIRFLOW_URL)/health" || { echo "âŒ webserver unhealthy"; exit 1; }
	@echo "âœ… webserver healthy"
	@echo "Check scheduler logs (last 50 lines)..."
	@$(COMPOSE) logs scheduler --tail 50
.PHONY: qa
qa: ## é›¶é—¨æ§›æœ¬åœ° QAï¼ˆparse + build + docsï¼‰
	@bash scripts/qa.sh
